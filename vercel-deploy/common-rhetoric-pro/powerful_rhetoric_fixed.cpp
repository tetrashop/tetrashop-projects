#include <iostream>
#include <string>
#include <vector>
#include <map>
#include <algorithm>
#include <memory>
#include <random>
#include <cmath>

/**
 * Ù†Ø·Ù‚ Ù…ØµØ·Ù„Ø­ - Ù†Ø³Ø®Ù‡ ØªØ¹Ù…ÛŒØ± Ø´Ø¯Ù‡ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ ÙˆØ§Ù‚Ø¹ÛŒ
 */

class AdvancedRhetoricAnalyzer {
private:
    std::map<std::string, double> word_power;
    std::map<std::string, int> word_frequency;
    
public:
    AdvancedRhetoricAnalyzer() {
        initialize_power_dictionary();
    }
    
    void initialize_power_dictionary() {
        // Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ù‚Ø¯Ø±Øª Ú©Ù„Ù…Ø§Øª ÙØ§Ø±Ø³ÛŒ
        word_power = {
            {"Ù…Ù‡Ù…", 0.8}, {"Ø§Ø³Ø§Ø³ÛŒ", 0.9}, {"Ø­ÛŒØ§ØªÛŒ", 0.95},
            {"ØªØ£Ø«ÛŒØ±Ú¯Ø°Ø§Ø±", 0.85}, {"Ú©Ø§Ø±Ø¢Ù…Ø¯", 0.75}, {"Ù…Ø¤Ø«Ø±", 0.8},
            {"Ù‚ÙˆÛŒ", 0.7}, {"Ù…Ø³ØªØ­Ú©Ù…", 0.75}, {"Ù¾Ø§ÛŒØ¯Ø§Ø±", 0.7}
        };
    }
    
    double analyze_sentence_power(const std::string& sentence) {
        double total_power = 0.0;
        int powerful_words = 0;
        
        std::vector<std::string> words = split_persian_text(sentence);
        
        for (const auto& word : words) {
            if (word_power.find(word) != word_power.end()) {
                total_power += word_power[word];
                powerful_words++;
            }
        }
        
        if (words.empty()) return 0.0;
        
        double power_density = powerful_words / static_cast<double>(words.size());
        double avg_power = powerful_words > 0 ? total_power / powerful_words : 0.0;
        
        return (power_density * 0.6 + avg_power * 0.4) * 0.8;
    }
    
    double calculate_clarity_score(const std::string& text) {
        // Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆØ¶ÙˆØ­ Ù…ØªÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ
        std::vector<std::string> sentences = split_sentences(text);
        if (sentences.empty()) return 0.0;
        
        double total_clarity = 0.0;
        for (const auto& sentence : sentences) {
            total_clarity += analyze_sentence_clarity(sentence);
        }
        
        return total_clarity / sentences.size();
    }
    
    std::string enhance_rhetorical_impact(const std::string& original) {
        std::string enhanced = original;
        
        // ØªÙ‚ÙˆÛŒØª Ø³Ø§Ø®ØªØ§Ø±ÛŒ
        enhanced = add_rhetorical_devices(enhanced);
        
        // Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù„Ù…Ø§Øª
        enhanced = replace_weak_words(enhanced);
        
        // Ø¨Ù‡Ø¨ÙˆØ¯ Ø¬Ø±ÛŒØ§Ù† Ù…ØªÙ†
        enhanced = improve_text_flow(enhanced);
        
        return enhanced;
    }
    
private:
    std::vector<std::string> split_persian_text(const std::string& text) {
        std::vector<std::string> words;
        std::string current_word;
        
        for (char c : text) {
            if (c == ' ' || c == '.' || c == 'ØŒ' || c == ';') {
                if (!current_word.empty()) {
                    words.push_back(current_word);
                    current_word.clear();
                }
            } else {
                current_word += c;
            }
        }
        
        if (!current_word.empty()) {
            words.push_back(current_word);
        }
        
        return words;
    }
    
    std::vector<std::string> split_sentences(const std::string& text) {
        std::vector<std::string> sentences;
        std::string current_sentence;
        
        for (char c : text) {
            current_sentence += c;
            if (c == '.' || c == '!' || c == 'ØŸ') {
                sentences.push_back(current_sentence);
                current_sentence.clear();
            }
        }
        
        if (!current_sentence.empty()) {
            sentences.push_back(current_sentence);
        }
        
        return sentences;
    }
    
    double analyze_sentence_clarity(const std::string& sentence) {
        std::vector<std::string> words = split_persian_text(sentence);
        if (words.empty()) return 0.0;
        
        // Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ ÙˆØ¶ÙˆØ­
        double avg_word_length = 0.0;
        for (const auto& word : words) {
            avg_word_length += word.length();
        }
        avg_word_length /= words.size();
        
        double word_variance = 0.0;
        for (const auto& word : words) {
            word_variance += std::pow(word.length() - avg_word_length, 2);
        }
        word_variance = std::sqrt(word_variance / words.size());
        
        // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ù…Ø±Ù‡ ÙˆØ¶ÙˆØ­
        double length_score = 1.0 - std::min(avg_word_length / 10.0, 1.0);
        double variance_penalty = std::min(word_variance / 5.0, 1.0);
        
        return length_score * (1.0 - variance_penalty * 0.3);
    }
    
    std::string add_rhetorical_devices(const std::string& text) {
        // Ø§ÙØ²ÙˆØ¯Ù† Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù„Ø§ØºÛŒ
        std::string enhanced = text;
        
        // Ø¯Ø± Ù†Ø³Ø®Ù‡ Ú©Ø§Ù…Ù„ØŒ Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ø´ÙˆÙ†Ø¯
        if (enhanced.length() > 20) {
            enhanced = "Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§Ù‡Ù…ÛŒØª Ù…ÙˆØ¶ÙˆØ¹ØŒ " + enhanced;
        }
        
        return enhanced;
    }
    
    std::string replace_weak_words(const std::string& text) {
        // Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ú©Ù„Ù…Ø§Øª Ø¶Ø¹ÛŒÙ Ø¨Ø§ Ù‚ÙˆÛŒ
        std::map<std::string, std::string> weak_to_strong = {
            {"Ø®ÙˆØ¨", "Ø¹Ø§Ù„ÛŒ"}, {"Ø¨Ø¯", "Ù†Ø§Ù…Ù†Ø§Ø³Ø¨"}, {"Ú©Ù…", "Ù†Ø§Ú©Ø§ÙÛŒ"}
        };
        
        std::string result = text;
        for (const auto& replacement : weak_to_strong) {
            size_t pos = 0;
            while ((pos = result.find(replacement.first, pos)) != std::string::npos) {
                result.replace(pos, replacement.first.length(), replacement.second);
                pos += replacement.second.length();
            }
        }
        
        return result;
    }
    
    std::string improve_text_flow(const std::string& text) {
        // Ø¨Ù‡Ø¨ÙˆØ¯ Ø¬Ø±ÛŒØ§Ù† Ù…ØªÙ†
        std::string improved = text;
        
        // Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
        size_t pos = 0;
        while ((pos = improved.find("  ", pos)) != std::string::npos) {
            improved.replace(pos, 2, " ");
        }
        
        // Ø§ØµÙ„Ø§Ø­ Ø¹Ù„Ø§Ø¦Ù… Ù†Ú¯Ø§Ø±Ø´ÛŒ
        pos = 0;
        while ((pos = improved.find(" .", pos)) != std::string::npos) {
            improved.replace(pos, 2, ".");
        }
        
        return improved;
    }
};

// ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ
int main() {
    std::cout << "ğŸ’ª Ù†Ø·Ù‚ Ù…ØµØ·Ù„Ø­ - Ù†Ø³Ø®Ù‡ ØªØ¹Ù…ÛŒØ± Ø´Ø¯Ù‡" << std::endl;
    
    AdvancedRhetoricAnalyzer analyzer;
    
    std::string sample_text = "Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³Øª Ú©Ù‡ Ø®ÙˆØ¨ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ù…Ø§ Ù…ÛŒ ØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ØªØ± Ø¨Ø§Ø´Ø¯.";
    
    double power = analyzer.analyze_sentence_power(sample_text);
    std::cout << "ğŸ’ª Ù‚Ø¯Ø±Øª Ø¨ÛŒØ§Ù†ÛŒ: " << power * 100 << "%" << std::endl;
    
    double clarity = analyzer.calculate_clarity_score(sample_text);
    std::cout   << "ğŸ” ÙˆØ¶ÙˆØ­ Ù…ØªÙ†: " << clarity * 100 << "%" << std::endl;
    
    std::string enhanced = analyzer.enhance_rhetorical_impact(sample_text);
    std::cout << "âœ¨ Ù…ØªÙ† ØªÙ‚ÙˆÛŒØª Ø´Ø¯Ù‡: " << enhanced << std::endl;
    
    return 0;
}
