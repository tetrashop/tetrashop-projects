# Real-time Speech Processing
# Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯ Ú¯ÙØªØ§Ø±

import queue
import threading
import time

class RealTimeSpeechProcessor:
    """
    Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯ Ú¯ÙØªØ§Ø±
    """
    
    def __init__(self, sample_rate: int = 16000):
        self.sample_rate = sample_rate
        self.audio_buffer = queue.Queue()
        self.is_processing = False
        self.results = []
        
    def start_processing(self):
        """Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯"""
        self.is_processing = True
        processing_thread = threading.Thread(target=self._process_stream)
        processing_thread.start()
        
        return processing_thread
    
    def stop_processing(self):
        """ØªÙˆÙ‚Ù Ù¾Ø±Ø¯Ø§Ø²Ø´"""
        self.is_processing = False
    
    def add_audio_chunk(self, audio_chunk: np.ndarray):
        """Ø§ÙØ²ÙˆØ¯Ù† Ø¨Ø®Ø´ ØµÙˆØªÛŒ Ø¨Ù‡ Ø¨Ø§ÙØ±"""
        self.audio_buffer.put(audio_chunk)
    
    def _process_stream(self):
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¬Ø±ÛŒØ§Ù† ØµÙˆØªÛŒ"""
        recognizer = PersianSpeechRecognizer()
        buffer_duration = 0.5  # Ø«Ø§Ù†ÛŒÙ‡
        chunk_size = int(self.sample_rate * buffer_duration)
        
        audio_chunks = []
        
        while self.is_processing:
            try:
                # Ø¯Ø±ÛŒØ§ÙØª chunk Ø§Ø² Ø¨Ø§ÙØ±
                chunk = self.audio_buffer.get(timeout=0.1)
                audio_chunks.append(chunk)
                
                # ÙˆÙ‚ØªÛŒ Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú©Ø§ÙÛŒ Ø¯Ø§Ø¯Ù‡ Ø¬Ù…Ø¹ Ø´Ø¯
                if len(audio_chunks) * len(chunk) >= chunk_size:
                    # ØªØ±Ú©ÛŒØ¨ chunks
                    combined = np.concatenate(audio_chunks)
                    
                    # Ù¾Ø±Ø¯Ø§Ø²Ø´
                    features = recognizer.extract_features(combined)
                    text = recognizer.recognize_speech(features)
                    
                    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡
                    self.results.append({
                        'timestamp': time.time(),
                        'text': text,
                        'confidence': np.random.uniform(0.85, 0.99)
                    })
                    
                    # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¨Ø§ÙØ±
                    audio_chunks = []
                    
            except queue.Empty:
                continue
    
    def get_results(self) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù†ØªØ§ÛŒØ¬"""
        return self.results

if __name__ == "__main__":
    print("ğŸ¤ Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯ Ú¯ÙØªØ§Ø±")
    print("=" * 40)
    
    # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯
    processor = RealTimeSpeechProcessor()
    
    print("â–¶ï¸  Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯...")
    thread = processor.start_processing()
    
    # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ±ÙˆØ¯ÛŒ ØµÙˆØªÛŒ
    for i in range(5):
        # ØªÙˆÙ„ÛŒØ¯ chunk ØµÙˆØªÛŒ ØªØµØ§Ø¯ÙÛŒ
        chunk = np.random.randn(8000)  # 0.5 Ø«Ø§Ù†ÛŒÙ‡
        processor.add_audio_chunk(chunk)
        
        print(f"  ğŸ”„ chunk {i+1} Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯")
        time.sleep(0.5)
    
    # ØªÙˆÙ‚Ù Ù¾Ø±Ø¯Ø§Ø²Ø´
    processor.stop_processing()
    thread.join()
    
    # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
    print("\nğŸ“Š Ù†ØªØ§ÛŒØ¬ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯:")
    for i, result in enumerate(processor.get_results()):
        time_str = time.strftime('%H:%M:%S', time.localtime(result['timestamp']))
        print(f"  [{time_str}] {result['text']} (Ø§Ø¹ØªÙ…Ø§Ø¯: {result['confidence']:.2%})")

